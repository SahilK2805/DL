sudo apt update
sudo apt install python3-pip -y
pip install notebook
!pip install numpy pandas matplotlib seaborn scikit-learn tensorflow








Experiment 2 MINST

ðŸ§  PART 1: What this experiment is about (super simple)
This experiment is about teaching a computer to recognize images â€” for example, pictures of digits (0 to 9) using a type of Deep Learning model called a Feedforward Neural Network (FFN).
Youâ€™ll use Keras (a library that makes Deep Learning easy) with TensorFlow (the backend that actually runs the math).
We are basically:
1.	Loading a dataset (like MNIST â€” images of handwritten digits).
2.	Preparing the data so the model can understand it.
3.	Building a small neural network (layers of neurons).
4.	Training it â€” making the computer learn from the images.
5.	Testing how well it learned.
6.	Plotting graphs to see the learning process.
Think of it like:
ðŸ« Training a student (model) to recognize numbers by showing thousands of examples (training data), and then testing the student with unseen examples (testing data).
________________________________________
ðŸ“˜ PART 2: Step-by-step notes (easy and exam-ready)
ðŸ§© Aim
To build and train a Feedforward Neural Network (FFN) using Keras and TensorFlow for classifying images (MNIST or CIFAR10).
________________________________________
ðŸ§  Theory (in simple words)
â€¢	A Feedforward Neural Network is a type of Artificial Neural Network where data moves only in one direction â€” from input â†’ hidden layers â†’ output.
â€¢	Each neuron receives inputs, multiplies them by weights, adds a bias, and applies an activation function to decide what to pass forward.
â€¢	By training, the network adjusts its weights to correctly map inputs to outputs.
For image classification:
â€¢	Input: pixel values of images (like 28Ã—28 = 784 numbers for MNIST).
â€¢	Hidden layers: detect patterns (edges, shapes, etc.).
â€¢	Output layer: gives probabilities for 10 classes (digits 0â€“9).
________________________________________
ðŸ§¾ Steps in the Experiment
Step 1. Import necessary libraries
We import:
import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
âž¡ These are the tools that let us build the neural network and plot results.
________________________________________
Step 2. Load dataset (MNIST or CIFAR10)
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
âž¡ Here we get:
â€¢	x_train: 60,000 images for training
â€¢	y_train: labels (0â€“9) for each image
â€¢	x_test: 10,000 images for testing
â€¢	y_test: labels for testing
Each MNIST image is 28Ã—28 pixels, black and white.
________________________________________
Step 3. Preprocess data
x_train = x_train.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0
x_train = x_train.reshape((60000, 784))
x_test = x_test.reshape((10000, 784))
âž¡ This step does:
1.	Converts data type to float.
2.	Divides by 255 â†’ so pixel values become between 0 and 1 (makes learning easier).
3.	Flattens each 28Ã—28 image into a single long row of 784 numbers.
________________________________________
Step 4. Build the neural network
model = keras.models.Sequential([
    keras.layers.Dense(512, activation='relu', input_shape=(784,)),
    keras.layers.Dense(256, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])
âž¡ Here:
â€¢	Sequential: means weâ€™re stacking layers one after another.
â€¢	Dense: means each neuron is connected to every neuron in the next layer.
â€¢	ReLU: activation function â†’ helps model learn complex patterns.
â€¢	Softmax: gives probability for each class (like [0.9, 0.1, 0, 0, ...]).
So, structure:
Input (784) â†’ Hidden Layer 1 (512 neurons)
            â†’ Hidden Layer 2 (256 neurons)
            â†’ Output Layer (10 neurons)
________________________________________
Step 5. Compile the model
model.compile(
    optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
âž¡ Explanation:
â€¢	Optimizer: SGD (Stochastic Gradient Descent) â†’ updates weights gradually to reduce error.
â€¢	Learning rate: how fast the model learns.
â€¢	Loss: measures how far predictions are from correct answers.
â€¢	Metrics: accuracy shows performance.
________________________________________
Step 6. Train the model
history = model.fit(x_train, y_train, epochs=15, batch_size=64, validation_split=0.1)
âž¡ Explanation:
â€¢	epochs: how many times the model sees the whole dataset.
â€¢	batch_size: how many samples to process before updating weights.
â€¢	validation_split: 10% data is used for checking accuracy after each epoch.
As it trains, it prints loss and accuracy for both training and validation data.
________________________________________
Step 7. Evaluate the model
model.evaluate(x_test, y_test)
âž¡ Checks how well the model performs on unseen test data.
________________________________________
Step 8. Plot graphs
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.show()
âž¡ Helps you visualize:
â€¢	Loss curve: should go down with time.
â€¢	Accuracy curve: should go up with time.
________________________________________
âœ… Result
The Feedforward Neural Network successfully learns to recognize handwritten digits.
Youâ€™ll see training accuracy â‰ˆ 97â€“99% and test accuracy â‰ˆ 96â€“98% for MNIST.
For CIFAR-10, it may be lower (~50â€“60%) because FFN is not ideal for color images.
________________________________________
ðŸ“Š Conclusion
â€¢	FFN can classify simple images by learning from pixel patterns.
â€¢	Accuracy depends on layer size, learning rate, and training epochs.
â€¢	For complex images, CNNs work better.
________________________________________
ðŸ’» PART 3: Code explanation (your notebook)
Hereâ€™s what each of your notebook sections does â€” simply put:
Cell	What it does	Simple meaning
1	Import libraries	Brings all required tools (TensorFlow, Keras, NumPy, Matplotlib).
2	Set seed values	Makes results repeatable.
3	Load dataset	Loads MNIST or CIFAR10 images & labels.
4	Preprocess data	Converts images to float, normalizes, flattens, adds channel dims.
5	Visual check	Displays a few training images to confirm they loaded correctly.
6	Define model	Creates the Feedforward Neural Network (input â†’ hidden â†’ output).
7	Compile model	Sets optimizer (SGD), loss, and accuracy metric.
8	Flatten images	Reshapes the data for input to Dense layers.
9	Train model	Runs model training for 15 epochs.
10	Plot graphs	Shows loss and accuracy over time.
11	Evaluate	Checks performance on test data.














Experiment 2 CIFAR

ðŸ§  PART 1: What this experiment is about (in simple words)
This experiment is about teaching a computer to recognize small color images (like airplanes, cars, dogs, etc.)
using a Feedforward Neural Network (FFN) â€” a basic type of Artificial Neural Network built using Keras and TensorFlow.
Youâ€™ll use the CIFAR-10 dataset, which has:
â€¢	50,000 training images
â€¢	10,000 testing images
â€¢	Each image is 32Ã—32 pixels, colored (3 channels), and belongs to one of 10 classes (airplane, bird, dog, etc.)
Here, weâ€™ll build a simple Dense Network (no convolution) to classify these images â€”
we flatten each image into a long row of numbers and train the model to map those pixels to the correct label.
ðŸ§© Think of it like teaching a student to identify objects just from colored pixel patterns.
________________________________________
ðŸ“˜ PART 2: Step-by-step notes (for journal / viva)
ðŸ§© Aim
To implement and train a Feedforward Neural Network (FFN) on the CIFAR-10 dataset using Keras and TensorFlow,
and evaluate its performance using Stochastic Gradient Descent (SGD) optimizer.
________________________________________
ðŸ§  Theory (in simple language)
â€¢	A Feedforward Neural Network (FFN) is the simplest type of Artificial Neural Network.
â€¢	Information moves only in one direction â€” from input â†’ hidden â†’ output layers.
â€¢	Each neuron has weights and biases, and uses an activation function to decide what output to pass forward.
â€¢	The model learns by adjusting weights so that its predicted outputs match the correct labels (using a loss function).
For CIFAR-10:
â€¢	Input: image pixels (32Ã—32Ã—3 = 3072 numbers)
â€¢	Hidden Layers: detect color and texture patterns
â€¢	Output: 10 neurons for 10 classes (softmax gives probabilities)
________________________________________
âš™ï¸ Algorithm / Steps
Step 1. Import necessary packages
import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
âž¡ Used for model building, training, and visualization.
________________________________________
Step 2. Load the CIFAR-10 dataset
(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()
âž¡ This gives:
â€¢	x_train: 50,000 images (32Ã—32Ã—3)
â€¢	y_train: corresponding labels (0â€“9)
â€¢	x_test: 10,000 test images
â€¢	y_test: labels for test images
________________________________________
Step 3. Preprocess the data
x_train = x_train.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0
x_train = x_train.reshape((x_train.shape[0], -1))
x_test = x_test.reshape((x_test.shape[0], -1))
âž¡ Converts pixel values (0â€“255) â†’ (0â€“1) range for better learning.
âž¡ Flattens each image (32Ã—32Ã—3 = 3072 numbers).
Now each image becomes a long vector of 3072 values.
________________________________________
Step 4. Define the neural network model
model = keras.models.Sequential([
    keras.layers.Input(shape=(3072,)),
    keras.layers.Dense(1024, activation='relu'),
    keras.layers.Dense(512, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])
âž¡ Sequential: stack layers in order
âž¡ Dense layers: fully connected neurons
âž¡ ReLU: makes the network learn non-linear features
âž¡ Softmax: converts outputs into class probabilities (for 10 categories)
________________________________________
Step 5. Compile the model
model.compile(
    optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
âž¡ Optimizer: SGD (updates weights to reduce error gradually)
âž¡ Loss: measures how wrong predictions are
âž¡ Metrics: accuracy (performance indicator)
________________________________________
Step 6. Train the model
history = model.fit(x_train, y_train, epochs=20, batch_size=64, validation_split=0.1)
âž¡ The model learns by repeatedly looking at the training images.
â€¢	Epochs: how many times it sees all images
â€¢	Batch size: number of images processed together
â€¢	Validation split: 10% used for checking accuracy after each epoch.
________________________________________
Step 7. Evaluate the model
model.evaluate(x_test, y_test)
âž¡ Tests the trained model on unseen images (test set)
âž¡ Prints test loss and test accuracy
________________________________________
Step 8. Plot training loss and accuracy
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend(); plt.show()
âž¡ Helps visualize how well the model is learning â€”
accuracy should go up, loss should go down.
________________________________________
ðŸ§¾ Result
â€¢	The Feedforward Neural Network successfully classifies CIFAR-10 images.
â€¢	Typical test accuracy is around 45â€“60% (since FFN isnâ€™t ideal for complex images).
â€¢	Adding more layers or using CNNs can improve accuracy significantly.
________________________________________
âœ… Conclusion
â€¢	The experiment shows how Feedforward Neural Networks can classify image data.
â€¢	Performance depends on the dataset complexity and network depth.
â€¢	FFNs work fine for simple data (like MNIST) but struggle with colored images (like CIFAR-10).
________________________________________
ðŸ’¬ Viva Questions
Question	Simple Answer
What is a Feedforward Neural Network?	A neural network where data flows only in one direction â€” from input to output.
What optimizer was used here?	Stochastic Gradient Descent (SGD).
What does ReLU do?	It removes negative values and keeps positive ones, helping the model learn faster.
Why do we normalize images?	To make all pixel values small (0â€“1), helping the model train efficiently.
What is softmax used for?	To convert the output into probabilities for multiple classes.
Why is accuracy lower for CIFAR-10?	Because FFN canâ€™t capture spatial features of color images like CNNs can.
________________________________________
ðŸ’» PART 3: Code Explanation (your notebook)
Step	Code Part	Explanation (in simple words)
Cell 1	Import libraries	Brings TensorFlow, Keras, Numpy, Matplotlib for deep learning and plotting.
Cell 2	Load dataset	Loads CIFAR-10 images (32Ã—32 color) and labels (0â€“9).
Cell 3	Preprocess data	Converts image pixels to [0,1] and reshapes for Dense input.
Cell 4	Build model	Creates Feedforward Neural Network (Dense layers).
Cell 5	Compile model	Selects optimizer (SGD), loss (cross-entropy), and accuracy metric.
Cell 6	Train model	Trains the FFN for several epochs using batches of 64.
Cell 7	Evaluate model	Calculates accuracy on unseen test data.
Cell 8	Plot accuracy/loss	Displays how well the model learned (accuracy up, loss down).
________________________________________
ðŸª„ Simple Analogy
Model Part	Real-World Example
Input layer	Eyes taking in the image
Hidden layers	Brain neurons recognizing colors and shapes
Output layer	Brain deciding the correct category (e.g., â€œdogâ€)















Experiment 3

ðŸ§  PART 1: What this experiment is about (in simple words)
This practical is about building an Image Classification Model using Keras and TensorFlow, step by step.
We train a computer to recognize images from the CIFAR-10 dataset â€” a popular dataset with:
â€¢	50,000 training images and 10,000 testing images
â€¢	Each image is 32Ã—32 pixels, color (RGB)
â€¢	There are 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck
The model is built in 4 stages:
1.	Loading and Preprocessing the image data
2.	Defining the Modelâ€™s Architecture
3.	Training the Model
4.	Estimating Model Performance (evaluation, graphs, confusion matrix)
________________________________________
ðŸ“˜ PART 2: Exam-ready notes (for your journal)
ðŸ§© Title
Build the Image Classification Model by dividing it into 4 stages:
a. Loading and preprocessing the image data
b. Defining the modelâ€™s architecture
c. Training the model
d. Estimating the modelâ€™s performance
________________________________________
ðŸŽ¯ Aim
To develop and train an image classification model using Keras and TensorFlow on the CIFAR-10 dataset, and evaluate its performance.
________________________________________
ðŸ§  Theory (in simple words)
â€¢	Image Classification means automatically predicting which class an image belongs to (for example, â€œdogâ€ or â€œcarâ€).
â€¢	A Convolutional Neural Network (CNN) or Feedforward Neural Network (FFN) can be used for this purpose.
â€¢	CNNs are better because they detect spatial features (edges, colors, shapes).
â€¢	The process includes:
1.	Loading the dataset
2.	Normalizing image pixel values (0â€“1 range)
3.	Building a neural network (layers)
4.	Training it to minimize loss
5.	Checking accuracy and visualizing results
________________________________________
âš™ï¸ Algorithm / Steps
Stage (a): Loading and Preprocessing the Image Data
(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()
x_train = x_train.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0
â€¢	Loads CIFAR-10 dataset
â€¢	Converts pixel values from 0â€“255 â†’ 0â€“1
â€¢	Prepares train and test sets for the model
âœ… Purpose: make the data ready for training (normalized and separated).
________________________________________
Stage (b): Defining the Model Architecture
model = keras.models.Sequential([
    keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),
    keras.layers.MaxPooling2D(2,2),
    keras.layers.Conv2D(64, (3,3), activation='relu'),
    keras.layers.MaxPooling2D(2,2),
    keras.layers.Flatten(),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])
âž¡ The model has:
1.	Conv2D Layers: detect patterns and features from images
2.	MaxPooling2D Layers: reduce image size and computation
3.	Flatten Layer: convert 2D features into a 1D vector
4.	Dense Layers: perform classification
5.	Softmax Layer: outputs probabilities for each of 10 classes
âœ… Purpose: define how the neural network looks and learns from data.
________________________________________
Stage (c): Training the Model
optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)
model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])
history = model.fit(x_train, y_train, epochs=12, batch_size=64, validation_split=0.1)
â€¢	SGD Optimizer: Stochastic Gradient Descent used to update weights
â€¢	Loss Function: measures how wrong predictions are
â€¢	Metrics: accuracy used to measure correctness
â€¢	The model learns from images for 12 epochs (12 passes over the dataset)
âœ… Purpose: train the neural network using CIFAR-10 images.
________________________________________
Stage (d): Estimating Model Performance
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f"Test Accuracy = {test_acc:.4f}")
âœ… Purpose: test the model on unseen data (test set) and get final accuracy.
You can also visualize results:
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.legend()
plt.show()
And analyze using a confusion matrix:
from sklearn.metrics import confusion_matrix
y_pred = model.predict(x_test)
cm = confusion_matrix(y_test, np.argmax(y_pred, axis=1))
sns.heatmap(cm, annot=True)
________________________________________
ðŸ“Š Result
â€¢	The model successfully classifies CIFAR-10 images.
â€¢	Typical test accuracy is around 70â€“80% (depending on architecture and epochs).
â€¢	The loss curve decreases while accuracy improves, showing effective training.
________________________________________
âœ… Conclusion
â€¢	The experiment demonstrates the full workflow of building an image classifier using deep learning.
â€¢	Dividing the process into stages (load, define, train, evaluate) helps understand each step clearly.
â€¢	CNNs work efficiently for image classification tasks.
________________________________________
ðŸ’¬ Viva Questions and Simple Answers
Question	Simple Answer
What dataset is used?	CIFAR-10, with 10 classes of colored images.
Why normalize the image data?	To keep pixel values small and make training stable.
What optimizer was used?	Stochastic Gradient Descent (SGD).
What is the activation function used?	ReLU for hidden layers, Softmax for output.
What is the purpose of the Flatten layer?	Converts 2D image data into a 1D vector before Dense layers.
What does a convolution layer do?	It extracts local features like edges or colors from the image.
What does pooling do?	Reduces the image size and helps the model focus on important features.
Why use softmax in output?	It converts model output into class probabilities.
________________________________________
ðŸ’» PART 3: Code explanation (your notebook stages)
Cell / Stage	Description (simple)
Cell 1	Imports libraries and sets random seeds for reproducibility.
Cell 2	Loads CIFAR-10 dataset and shows an example image.
Cell 3	Applies data preprocessing and optional data augmentation.
Cell 4	Defines CNN model architecture using Conv, Pooling, Flatten, and Dense layers.
Cell 5	Compiles model using SGD optimizer.
Cell 6	Trains the model for 12 epochs with callbacks (checkpoint, early stopping).
Cell 7	Plots accuracy and loss curves for training and validation.
Cell 8	Evaluates model on test set and prints accuracy.
Cell 9	Displays confusion matrix and classification report for deeper analysis.
________________________________________
ðŸª„ Simple Analogy
Neural Network Part	Real-life Comparison
Input Layer	Eyes seeing the picture
Convolution + Pooling	Brain extracting features like color and shape
Dense Layers	Brain deciding what object it is
Output (Softmax)	Final decision (â€œthis is a dog!â€)
















Experiment 4

ðŸ§  PART 1 â€” What the experiment is about (very simple)
An autoencoder is a neural network that learns to reconstruct its input.
For anomaly detection we:
1.	Train the autoencoder on normal data only (examples without anomalies).
2.	Later, give it new inputs â€” if the reconstruction error is low, input is normal; if high, input is likely an anomaly.
Think: train the network to copy normal images. If it fails badly to copy a new image, that image is unusual.
________________________________________
ðŸ“˜ PART 2 â€” Exam-ready notes (short & printable)
Title: Use Autoencoder to implement anomaly detection
Aim: Build an autoencoder using Keras/TensorFlow, train it on normal data, and detect anomalies by thresholding reconstruction error.
Dataset (example): MNIST (60k train, 10k test). Choose one digit as â€œnormalâ€ (e.g., digit 1) and treat other digits as anomalies for testing.
Autoencoder idea:
â€¢	Encoder: compresses input â†’ latent vector (small d).
â€¢	Decoder: reconstructs latent â†’ original input size.
â€¢	Training objective: minimize reconstruction error (e.g., MSE).
â€¢	Anomaly decision: reconstruction error > threshold â†’ anomaly.
Preprocessing:
â€¢	Normalize pixel values to [0,1]
â€¢	Flatten images for a dense autoencoder, or keep 2D for convolutional autoencoder
Model (examples):
â€¢	Dense autoencoder: Input(784) â†’ Dense(128) â†’ Dense(32) (latent) â†’ Dense(128) â†’ Dense(784)
â€¢	Conv autoencoder: Conv2D â†’ MaxPool â†’ Conv2D (bottleneck) â†’ Conv2DTranspose â†’ Upsampling â†’ Output
Compile settings (example):
â€¢	Optimizer: Adam or SGD
â€¢	Loss: mean_squared_error or binary_crossentropy
â€¢	Metrics: mae (mean absolute error) or custom reconstruction error
Training:
â€¢	Train on normal samples only (epochs 20â€“50, batch_size 64)
â€¢	Save validation loss to detect overfitting
Anomaly detection:
â€¢	Compute reconstruction error for test samples
â€¢	Choose threshold (e.g., mean_train_error + 3 * std_train_error) or via ROC curve
â€¢	Evaluate: precision, recall, F1-score, confusion matrix
Conclusion: Autoencoders can detect anomalies that differ from the normal training distribution. For complex anomalies or images, convolutional autoencoders perform better.
________________________________________
âš™ï¸ PART 3 â€” Step-by-step algorithm (mapping to your aâ†’e)
a. Import required libraries
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
b. Upload / access dataset
â€¢	Example: keras.datasets.mnist.load_data()
â€¢	Choose normal class (e.g., label == 1) for training
c. Encoder converts to latent representation
â€¢	Build encoder layers that shrink the input to a small latent vector (e.g., 32 dims)
d. Decoder converts latent back
â€¢	Symmetric decoder that expands latent to original input shape
e. Compile the model
â€¢	optimizer=Adam(lr=0.001), loss='mse', track metrics like mae
________________________________________
ðŸ’» PART 4 â€” Ready-to-run Keras code (Dense autoencoder on MNIST)
Copy & paste into a cell or save as autoencoder_anomaly_mnist.py. This trains on one digit (normal) and tests on others as anomalies.
# Autoencoder for Anomaly Detection (MNIST example)
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix

# 1) Load dataset
(x_train_full, y_train_full), (x_test_full, y_test_full) = keras.datasets.mnist.load_data()

# Choose normal class (e.g., digit 1). Train only on normal samples.
NORMAL_CLASS = 1
x_train = x_train_full[y_train_full.flatten() == NORMAL_CLASS]
y_train = y_train_full[y_train_full.flatten() == NORMAL_CLASS]

# For testing, keep both normal and anomaly examples
x_test = x_test_full.copy()
y_test = y_test_full.copy()

# 2) Preprocess: scale to [0,1] and flatten
x_train = x_train.astype('float32') / 255.0
x_test  = x_test.astype('float32') / 255.0
x_train = x_train.reshape((x_train.shape[0], -1))  # 28*28 = 784
x_test  = x_test.reshape((x_test.shape[0], -1))

# 3) Build dense autoencoder
input_dim = x_train.shape[1]  # 784
latent_dim = 32

# Encoder
inputs = keras.Input(shape=(input_dim,))
h = keras.layers.Dense(128, activation='relu')(inputs)
h = keras.layers.Dense(64, activation='relu')(h)
latent = keras.layers.Dense(latent_dim, activation='relu', name='latent')(h)

# Decoder
h2 = keras.layers.Dense(64, activation='relu')(latent)
h2 = keras.layers.Dense(128, activation='relu')(h2)
outputs = keras.layers.Dense(input_dim, activation='sigmoid')(h2)  # sigmoid because input is [0,1]

autoencoder = keras.Model(inputs, outputs, name='autoencoder')
encoder = keras.Model(inputs, latent, name='encoder')  # for inspection/visualizing latent

# 4) Compile the model
autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),
                    loss='mse',
                    metrics=[keras.metrics.MeanAbsoluteError()])

autoencoder.summary()

# 5) Train on normal images only
history = autoencoder.fit(x_train, x_train,
                          epochs=30,
                          batch_size=128,
                          validation_split=0.1,
                          verbose=2)

# 6) Compute reconstruction error on training set to set threshold
recon_train = autoencoder.predict(x_train)
train_mse = np.mean(np.square(recon_train - x_train), axis=1)
threshold = np.mean(train_mse) + 3 * np.std(train_mse)
print("Threshold (mean + 3*std) =", threshold)

# 7) Apply to test set: compute per-sample reconstruction MSE
recon_test = autoencoder.predict(x_test)
test_mse = np.mean(np.square(recon_test - x_test), axis=1)

# Make anomaly predictions: 1 if anomaly, 0 if normal
y_true = (y_test.flatten() != NORMAL_CLASS).astype(int)  # anomalies = 1
y_pred = (test_mse > threshold).astype(int)

# 8) Evaluation metrics
prec = precision_score(y_true, y_pred)
rec = recall_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred)
cm = confusion_matrix(y_true, y_pred)

print(f"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}")
print("Confusion Matrix (rows: true [0 normal,1 anomaly]; cols: pred [0 normal,1 anomaly])")
print(cm)

# 9) Plot a few examples: original, reconstruction, mse
n = 6
plt.figure(figsize=(12,6))
for i in range(n):
    ax = plt.subplot(3, n, i+1)
    plt.imshow(x_test[i].reshape(28,28), cmap='gray')
    plt.title(f"True:{y_test[i][0]}")
    plt.axis('off')

    ax = plt.subplot(3, n, i+1+n)
    plt.imshow(recon_test[i].reshape(28,28), cmap='gray')
    plt.title(f"Recon")
    plt.axis('off')

    ax = plt.subplot(3, n, i+1+2*n)
    plt.plot((x_test[i] - recon_test[i])**2)
    plt.title(f"MSE:{test_mse[i]:.4f}")
    plt.axis('off')
plt.tight_layout(); plt.show()
________________________________________
ðŸ”Ž PART 5 â€” Short explanation of the code (line-by-line highlights)
â€¢	Loading data: keras.datasets.mnist.load_data() gives arrays of images and labels.
â€¢	Selecting normal class: we only keep samples of NORMAL_CLASS for training the autoencoder.
â€¢	Preprocessing: scale to [0,1] and flatten images to make them vectors for a dense autoencoder.
â€¢	Model: encoder reduces 784 â†’ 128 â†’ 64 â†’ 32 (latent). Decoder mirrors that to reconstruct original 784 pixels.
â€¢	Compile: use Adam optimizer, mse loss (suitable for reconstruction), track mae as metric.
â€¢	Train: model learns to reconstruct normal samples.
â€¢	Threshold: compute train reconstruction error distribution and pick mean + 3*std as a simple threshold.
â€¢	Predict anomalies: test samples with reconstruction MSE > threshold are anomalies.
â€¢	Evaluate: precision, recall, F1 and confusion matrix compare predicted anomalies to true anomalies (we defined anomaly = any digit â‰  normal digit).
â€¢	Plot: show original vs reconstruction and MSE to visualize detection.
________________________________________
âœ… PART 6 â€” Interpretation & tips (simple)
â€¢	If the autoencoder is trained only on normal data, it should reconstruct them well (low error) and reconstruct anomalies poorly (high error).
â€¢	The threshold choice matters â€” adjust using validation set or ROC curve to get desired precision/recall.
â€¢	For image tasks, convolutional autoencoders (Conv2D + Conv2DTranspose) usually give much better reconstructions than dense autoencoders.
â€¢	If anomalies are subtle, consider more powerful models or using latent-space anomaly scoring.
________________________________________
ðŸ’¬ PART 7 â€” Quick Viva Qs (with one-line answers)
Q: Why train autoencoder only on normal samples?
A: Because the model must learn the normal data distribution; anomalies will then produce high reconstruction error.
Q: Which loss is used for reconstruction?
A: MSE (mean squared error) is common; binary_crossentropy can be used when inputs are binary-like.
Q: How choose threshold for anomaly?
A: Statistical rule (mean + k*std), or choose threshold by ROC/AUC on validation data.
Q: Why use convolutional autoencoder for images?
A: Conv layers capture spatial patterns and local features (edges, textures), improving reconstruction for images.





















Experiment 5

ðŸ§  PART 1: What this experiment is about (in simple words)
This experiment shows how to build a Continuous Bag of Words (CBOW) model â€” a type of Word2Vec neural network used in Natural Language Processing (NLP).
CBOW learns word embeddings â€” i.e., converts words into numeric vectors that capture meaning.
ðŸ’¡ Idea:
Given a few surrounding words (context), predict the target word.
For example:
In the sentence â†’ â€œThe cat sits on the matâ€
If we take context = [â€œTheâ€, â€œsitsâ€], then the target word is â€œcatâ€.
The model learns to predict words from their neighbors â€” this helps it understand semantic meaning (e.g., â€œkingâ€ and â€œqueenâ€ get similar vector patterns).
________________________________________
ðŸ“˜ PART 2: Exam-ready Notes (for journal)
ðŸ§© Title
Implement the Continuous Bag of Words (CBOW) Model.
Stages:
a. Data Preparation
b. Generate Training Data
c. Train Model
d. Output
________________________________________
ðŸŽ¯ Aim
To implement the Continuous Bag of Words (CBOW) model using a small text dataset and train it to learn meaningful word embeddings.
________________________________________
ðŸ§  Theory (in simple words)
â€¢	Word2Vec is a neural network-based model that converts words into dense vector representations (embeddings).
â€¢	CBOW and Skip-gram are two architectures of Word2Vec.
â€¢	CBOW predicts a word from its context (surrounding words).
â€¢	Skip-gram does the opposite â€” predicts surrounding words from a given word.
â€¢	CBOW uses a simple neural network with:
o	Input layer: context words
o	Hidden layer: embedding (vector representation)
o	Output layer: target word (probability for each word)
Example:
Context: ["I", "machine"]
Target: "love"
Model learns:
â†’ If "I" and "machine" appear around "love", then "love" is strongly related to them.
________________________________________
âš™ï¸ Algorithm / Steps
Stage (a): Data Preparation
1.	Collect a small text corpus (few sentences).
2.	Convert text to lowercase and split into words (tokenize).
3.	Create a vocabulary (unique words â†’ numeric indices).
Example:
corpus = "I love machine learning and deep learning"
tokens = corpus.lower().split()
vocab = set(tokens)
word2idx = {w:i for i,w in enumerate(vocab)}
________________________________________
Stage (b): Generate Training Data
1.	Define context window size (e.g., 2 words before and after the target).
2.	For each target word, collect its context words.
3.	Convert words to indices using word2idx.
Example:
def generate_training_data(tokens, window_size):
    data = []
    for i in range(window_size, len(tokens) - window_size):
        context = [tokens[i - window_size + j] for j in range(2 * window_size) if j != window_size]
        target = tokens[i]
        data.append((context, target))
    return data
________________________________________
Stage (c): Train the Model
1.	Build a simple neural network in Keras:
o	Input â†’ Embedding â†’ Average â†’ Dense â†’ Softmax
2.	Train it using context words as input, target word as output.
Example:
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Lambda, Dense
from tensorflow.keras.preprocessing.sequence import skipgrams
import tensorflow.keras.backend as K

# parameters
vocab_size = len(vocab)
embed_dim = 8

# CBOW model
model = Sequential()
model.add(Embedding(vocab_size, embed_dim, input_length=2*window_size))
model.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(embed_dim,)))
model.add(Dense(vocab_size, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam')
________________________________________
Stage (d): Output
1.	After training, extract the word embeddings.
2.	Find similar words by comparing embeddings (using cosine similarity).
3.	Visualize or print embeddings for interpretation.
Example:
weights = model.get_weights()[0]
for word, idx in word2idx.items():
    print(f"{word}: {weights[idx]}")
________________________________________
ðŸ“Š Result
â€¢	The CBOW model successfully learns word embeddings from text.
â€¢	Words used in similar contexts have similar vector values.
â€¢	These embeddings can be used for other NLP tasks (classification, translation, etc.).
________________________________________
âœ… Conclusion
â€¢	CBOW efficiently learns relationships between words.
â€¢	It captures the semantic meaning and contextual similarity between words.
â€¢	For small datasets, results are basic; with large corpora (like Google News), embeddings become highly accurate.
________________________________________
ðŸ’¬ PART 3: Viva Questions (simple answers)
Question	Answer
What is CBOW?	A model that predicts a target word based on surrounding context words.
What is Skip-gram?	Opposite of CBOW; predicts context words from a single target word.
What is a word embedding?	A numeric vector representation of a word that captures its meaning.
Which layer is used for embeddings?	The Embedding layer in Keras.
What is the output of CBOW?	A probability distribution over all words (predicted target word).
Which activation function is used at the output layer?	Softmax.
Which optimizer is commonly used?	Adam or SGD.
What is context window size?	Number of words used before and after the target word.
________________________________________
ðŸ’» PART 4: Full Example Code (Simple Keras Implementation)
# Continuous Bag of Words (CBOW) model example

import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Lambda, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.utils import to_categorical
import tensorflow.keras.backend as K

# Stage (a) â€” Data Preparation
corpus = "I love machine learning and deep learning"
corpus = corpus.lower().split()

tokenizer = Tokenizer()
tokenizer.fit_on_texts(corpus)
word2idx = tokenizer.word_index
idx2word = {v:k for k,v in word2idx.items()}
vocab_size = len(word2idx) + 1

# Stage (b) â€” Generate Training Data
window_size = 2
data = []
for i in range(window_size, len(corpus) - window_size):
    context = [corpus[i - 2], corpus[i - 1], corpus[i + 1], corpus[i + 2]]
    target = corpus[i]
    data.append((context, target))

X = []
y = []
for context, target in data:
    X.append([word2idx[w] for w in context])
    y.append(to_categorical(word2idx[target], vocab_size))

X = np.array(X)
y = np.array(y)

# Stage (c) â€” Build and Train Model
model = Sequential()
model.add(Embedding(vocab_size, 8, input_length=4))
model.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(8,)))
model.add(Dense(vocab_size, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model.fit(X, y, epochs=100, verbose=0)
print("âœ… Training complete!")

# Stage (d) â€” Output
weights = model.get_weights()[0]
for word, idx in word2idx.items():
    print(f"{word}: {weights[idx]}")
________________________________________
ðŸª„ Simple Analogy
CBOW concept	Real-life comparison
Context words	Clues around a missing word
Target word	The missing word itself
Embedding layer	Brain forming understanding of word meaning
Softmax output	Guessing the correct word






Experiment 6

ðŸ§  PART 1: What this experiment is about (in simple words)
This experiment shows how to perform Object Detection / Image Classification using Transfer Learning â€”
a method where we reuse a pre-trained CNN (like VGG16, ResNet, or MobileNet) that has already learned features from a large dataset (e.g., ImageNet).
Instead of training from scratch, we:
1.	Load a pre-trained CNN model
2.	Freeze its early layers (they already know how to detect general features like edges, shapes)
3.	Add new classifier layers on top for our specific dataset
4.	Train only the new layers
5.	Optionally unfreeze deeper layers and fine-tune them for better accuracy.
ðŸ§© Think of it like taking a student who already knows how to recognize shapes and teaching them to recognize a new type of object faster â€” instead of starting from zero.
________________________________________
ðŸ“˜ PART 2: Exam-Ready Notes
ðŸ§© Title
Object Detection using Transfer Learning of CNN Architectures
________________________________________
ðŸŽ¯ Aim
To build an object detection/classification model using transfer learning with a pre-trained CNN,
by freezing early layers and training new classifier layers for the given dataset.
________________________________________
ðŸ§  Theory (in simple words)
â€¢	CNN (Convolutional Neural Network) models like VGG16, ResNet50, InceptionV3, and MobileNet are trained on massive datasets like ImageNet with millions of images.
â€¢	These networks learn to detect low-level features (edges, shapes, colors) and high-level features (objects, textures).
â€¢	Transfer Learning uses these pre-learned features and adapts them to a smaller, specific dataset â€” saving time and improving performance.
â€¢	Steps:
1.	Load a pre-trained CNN (e.g., VGG16)
2.	Freeze the convolutional base layers
3.	Add new Dense layers for classification
4.	Train only these new layers
5.	Optionally unfreeze some deeper layers and fine-tune for accuracy
________________________________________
âš™ï¸ Algorithm / Steps
(a) Load a pre-trained CNN model
from tensorflow.keras.applications import VGG16

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.summary()
âœ… Loads VGG16 pre-trained on ImageNet
âœ… include_top=False removes the last classification layers
âœ… Keeps the convolutional base for feature extraction
________________________________________
(b) Freeze parameters (weights) in modelâ€™s lower layers
for layer in base_model.layers:
    layer.trainable = False
âœ… Freezes weights â€” early layers wonâ€™t change during training
âœ… Prevents loss of pre-learned general image features
________________________________________
(c) Add custom classifier layers
from tensorflow.keras import models, layers

model = models.Sequential([
    base_model,
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(num_classes, activation='softmax')
])
âœ… Adds new layers for your dataset (e.g., animals, vehicles, etc.)
âœ… These layers are trainable and learn new object-specific patterns
________________________________________
(d) Train classifier layers
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(train_data, validation_data=val_data, epochs=10)
âœ… Uses Adam optimizer for faster convergence
âœ… Trains only top layers (base model is frozen)
âœ… Monitors validation accuracy to check generalization
________________________________________
(e) Fine-tune and unfreeze layers
# Unfreeze deeper layers for fine-tuning
for layer in base_model.layers[-4:]:
    layer.trainable = True

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),
              loss='categorical_crossentropy',
              metrics=['accuracy'])
history_fine = model.fit(train_data, validation_data=val_data, epochs=5)
âœ… Carefully unfreezes the last few convolutional layers
âœ… Fine-tunes them on your specific dataset with a smaller learning rate
âœ… Improves accuracy further
________________________________________
ðŸ“Š Result
â€¢	The transfer learning model successfully classifies images with high accuracy (usually >90% for small datasets).
â€¢	Training time is much shorter compared to building a CNN from scratch.
â€¢	Model learns both general (edges, textures) and task-specific features.
________________________________________
âœ… Conclusion
â€¢	Transfer Learning reuses pre-trained CNN knowledge to efficiently solve new tasks.
â€¢	Freezing lower layers preserves general visual features.
â€¢	Fine-tuning deeper layers improves model accuracy.
â€¢	This method is widely used in modern computer vision (e.g., image classification, object detection, medical imaging).
________________________________________
ðŸ’¬ PART 3: Viva Questions (Simple Answers)
Question	Answer (Simple)
What is Transfer Learning?	Using a model pre-trained on one dataset for another similar task.
Why freeze the base layers?	To keep general visual features learned from large datasets.
Why add new layers?	To train on new, task-specific classes.
What dataset is the base model pre-trained on?	ImageNet (commonly used, with 1,000 classes).
What optimizer is used?	Adam or SGD.
What happens if you unfreeze too many layers?	The model may overfit or forget earlier knowledge (catastrophic forgetting).
What is fine-tuning?	Adjusting a few layers of a pre-trained model with a low learning rate.
Why use dropout?	To prevent overfitting during training.
What are examples of pre-trained models?	VGG16, ResNet50, MobileNet, InceptionV3, EfficientNet.
________________________________________
ðŸ’» PART 4: Full Example Code (Simple and Ready-to-Run)
# Transfer Learning for Object Classification (VGG16 Example)

import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# (a) Load pretrained VGG16 model
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
for layer in base_model.layers:
    layer.trainable = False  # (b) Freeze base layers

# (c) Add custom classifier layers
model = models.Sequential([
    base_model,
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(3, activation='softmax')  # Example: 3 classes
])

# Data generators for train/validation
train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)
train_data = train_datagen.flow_from_directory(
    'dataset/train', target_size=(224, 224), batch_size=32, subset='training')
val_data = train_datagen.flow_from_directory(
    'dataset/train', target_size=(224, 224), batch_size=32, subset='validation')

# (d) Train classifier
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(train_data, validation_data=val_data, epochs=10)

# (e) Fine-tuning: unfreeze last few layers
for layer in base_model.layers[-4:]:
    layer.trainable = True

model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),
              loss='categorical_crossentropy', metrics=['accuracy'])
history_fine = model.fit(train_data, validation_data=val_data, epochs=5)

# Evaluate model
loss, acc = model.evaluate(val_data)
print(f"Validation Accuracy: {acc*100:.2f}%")
________________________________________
ðŸª„ Simple Analogy
Transfer Learning Step	Real-Life Example
Pre-trained CNN	A person already trained to recognize general objects
Freeze layers	Donâ€™t change what they already know
Add classifier	Teach them to identify new objects
Train top layers	They learn new things quickly
Fine-tune deeper layers	Refine their understanding for higher accuracy

