{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c87e0399-7e21-48a4-95c4-07fb94c304d5",
      "metadata": {
        "id": "c87e0399-7e21-48a4-95c4-07fb94c304d5"
      },
      "outputs": [],
      "source": [
        "# ---------------- Cell 1: Imports & reproducibility ----------------\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69f0c1e2-bbb6-4a87-adde-c1af2544e7d4",
      "metadata": {
        "id": "69f0c1e2-bbb6-4a87-adde-c1af2544e7d4"
      },
      "outputs": [],
      "source": [
        "# ---------------- Cell 2: Configure dataset paths and params ----------------\n",
        "# Replace these with your actual directories\n",
        "TRAIN_DIR = \"dataset/train/\"   # should contain subfolders for each class\n",
        "VAL_DIR   = \"dataset/val/\"     # optional, else use validation_split in generator\n",
        "TEST_DIR  = \"dataset/test/\"    # optional\n",
        "\n",
        "# Image sizing and batch\n",
        "IMG_SIZE = (224, 224)   # common for most pretrained nets; change to (32,32) for small nets\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = None      # will be inferred from generator\n",
        "\n",
        "# Set this to 'mobilenet' or 'vgg16' or 'resnet50' depending on the backbone you want\n",
        "BACKBONE = \"mobilenet\"  # options: \"mobilenet\", \"vgg16\", \"resnet50\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "424c3e84-3143-4b9f-99ba-37409d825cd3",
      "metadata": {
        "id": "424c3e84-3143-4b9f-99ba-37409d825cd3"
      },
      "outputs": [],
      "source": [
        "# ------------------ Safe CIFAR-10 fallback using tf.data (replacement) ------------------\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Ensure IMG_SIZE, BATCH_SIZE, SEED are defined — set sensible defaults if not\n",
        "try:\n",
        "    IMG_SIZE\n",
        "except NameError:\n",
        "    IMG_SIZE = (224, 224)   # you can reduce to (128,128) or (96,96) if still tight on memory\n",
        "try:\n",
        "    BATCH_SIZE\n",
        "except NameError:\n",
        "    BATCH_SIZE = 32\n",
        "try:\n",
        "    SEED\n",
        "except NameError:\n",
        "    SEED = 42\n",
        "\n",
        "print(\"Using CIFAR-10 fallback. Lazy resizing via tf.data to avoid OOM.\")\n",
        "(x_train_all, y_train_all), (x_test_all, y_test_all) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Flatten label arrays\n",
        "y_train_all = y_train_all.flatten()\n",
        "y_test_all  = y_test_all.flatten()\n",
        "\n",
        "# We'll create a train/val split from CIFAR train set (10% val)\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "    x_train_all, y_train_all, test_size=0.1, random_state=SEED, stratify=y_train_all\n",
        ")\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "class_indices = {\n",
        "    'airplane':0,'automobile':1,'bird':2,'cat':3,'deer':4,\n",
        "    'dog':5,'frog':6,'horse':7,'ship':8,'truck':9\n",
        "}\n",
        "\n",
        "# Preprocessing functions (applied per-sample)\n",
        "def preprocess_train(image, label):\n",
        "    # convert to float [0,1]\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    # resize (done per image to avoid creating huge tensor at once)\n",
        "    image = tf.image.resize(image, IMG_SIZE)\n",
        "    # simple augmentation (random flip + slight random brightness)\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.08)\n",
        "    # ensure shape\n",
        "    image.set_shape([IMG_SIZE[0], IMG_SIZE[1], 3])\n",
        "    label = tf.one_hot(label, NUM_CLASSES)\n",
        "    return image, label\n",
        "\n",
        "def preprocess_val(image, label):\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    image = tf.image.resize(image, IMG_SIZE)\n",
        "    image.set_shape([IMG_SIZE[0], IMG_SIZE[1], 3])\n",
        "    label = tf.one_hot(label, NUM_CLASSES)\n",
        "    return image, label\n",
        "\n",
        "# Create tf.data datasets (these do not allocate entire resized arrays at once)\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_tr, y_tr))\n",
        "train_ds = train_ds.shuffle(buffer_size=5000, seed=SEED)\n",
        "train_ds = train_ds.map(preprocess_train, num_parallel_calls=AUTOTUNE)\n",
        "train_ds = train_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "val_ds = val_ds.map(preprocess_val, num_parallel_calls=AUTOTUNE)\n",
        "val_ds = val_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "print(\"train_ds element spec:\", train_ds.element_spec)\n",
        "print(\"val_ds element spec  :\", val_ds.element_spec)\n",
        "print(\"NUM_CLASSES:\", NUM_CLASSES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73c1dda8-3cab-45e3-ac01-eefc8125a6e1",
      "metadata": {
        "id": "73c1dda8-3cab-45e3-ac01-eefc8125a6e1"
      },
      "outputs": [],
      "source": [
        "# ---------------- Cell 4: Load pretrained backbone (without top) ----------------\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "if BACKBONE == \"mobilenet\":\n",
        "    base_model = keras.applications.MobileNetV2(\n",
        "        input_shape=(*IMG_SIZE, 3), include_top=False, weights='imagenet'\n",
        "    )\n",
        "elif BACKBONE == \"resnet50\":\n",
        "    base_model = keras.applications.ResNet50(\n",
        "        input_shape=(*IMG_SIZE, 3), include_top=False, weights='imagenet'\n",
        "    )\n",
        "elif BACKBONE == \"vgg16\":\n",
        "    base_model = keras.applications.VGG16(\n",
        "        input_shape=(*IMG_SIZE, 3), include_top=False, weights='imagenet'\n",
        "    )\n",
        "else:\n",
        "    raise ValueError(\"BACKBONE must be one of: mobilenet, resnet50, vgg16\")\n",
        "\n",
        "# Print summary of backbone\n",
        "base_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "224c8fe0-8e0b-4d6d-bf5c-e24823a4b271",
      "metadata": {
        "id": "224c8fe0-8e0b-4d6d-bf5c-e24823a4b271"
      },
      "outputs": [],
      "source": [
        "# ---------------- Cell 5: Freeze lower layers (all for initial training) ----------------\n",
        "# Freeze all layers first (so only classifier head trains)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "print(\"Backbone trainable layers after freeze:\", sum([1 for l in base_model.layers if l.trainable]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8f445cd-3fa9-4bab-9a8b-3e361fc9c25f",
      "metadata": {
        "id": "b8f445cd-3fa9-4bab-9a8b-3e361fc9c25f"
      },
      "outputs": [],
      "source": [
        "# ---------------- Cell 6: Add custom classifier head ----------------\n",
        "# Typical head: GlobalAveragePooling -> Dense -> Dropout -> Dense(num_classes, softmax)\n",
        "inputs = keras.Input(shape=(*IMG_SIZE, 3))\n",
        "x = base_model(inputs, training=False)   # pass training=False so BN layers run in inference mode while frozen\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model = models.Model(inputs, outputs, name=f\"{BACKBONE}_transfer\")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c71a89a-4993-4e80-af99-fef7885141ba",
      "metadata": {
        "id": "7c71a89a-4993-4e80-af99-fef7885141ba"
      },
      "outputs": [],
      "source": [
        "# ---------------- Cell 7: Compile model (train only head) ----------------\n",
        "# Use SGD as requested (or Adam). SGD with momentum is common for fine-tuning.\n",
        "initial_lr = 1e-3\n",
        "optimizer = keras.optimizers.SGD(learning_rate=initial_lr, momentum=0.9)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "297465c6-3f1e-40da-9e6e-930d47b5c992",
      "metadata": {
        "id": "297465c6-3f1e-40da-9e6e-930d47b5c992"
      },
      "outputs": [],
      "source": [
        "# ---------------- Cell 8: Callbacks ----------------\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"best_transfer_model.keras\", save_best_only=True, monitor=\"val_loss\")\n",
        "earlystop_cb = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "reduce_lr_cb = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3)\n",
        "\n",
        "callbacks = [checkpoint_cb, earlystop_cb, reduce_lr_cb]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78102ba6-79f3-4e83-a032-237df9b726db",
      "metadata": {
        "id": "78102ba6-79f3-4e83-a032-237df9b726db"
      },
      "outputs": [],
      "source": [
        "# ---------------- Fixed Cell 9 — Train classifier head ----------------\n",
        "EPOCHS_HEAD = 1  # number of epochs for the frozen backbone stage\n",
        "\n",
        "# Pick whichever dataset variables exist\n",
        "if \"train_ds\" in locals():\n",
        "    train_data = train_ds\n",
        "    val_data = val_ds\n",
        "    print(\"Training on tf.data datasets (CIFAR-10 fallback).\")\n",
        "elif \"train_gen\" in locals():\n",
        "    train_data = train_gen\n",
        "    val_data = val_gen\n",
        "    print(\"Training on ImageDataGenerator generators (custom dataset).\")\n",
        "else:\n",
        "    raise NameError(\"No training dataset found. Define train_ds/val_ds or train_gen/val_gen first.\")\n",
        "\n",
        "history_head = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=EPOCHS_HEAD,\n",
        "    callbacks=callbacks,\n",
        "    verbose=2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfa7bc4a-0949-4d27-82cb-c9d832af9883",
      "metadata": {
        "id": "bfa7bc4a-0949-4d27-82cb-c9d832af9883"
      },
      "outputs": [],
      "source": [
        "# ---------------- Cell 10: Evaluate after head training ----------------\n",
        "val_loss, val_acc = model.evaluate(val_ds, verbose=0)\n",
        "print(f\"Validation loss: {val_loss:.4f}, Validation accuracy: {val_acc:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ca310bd-a176-4bd1-adb1-e781a5c117e0",
      "metadata": {
        "id": "1ca310bd-a176-4bd1-adb1-e781a5c117e0"
      },
      "outputs": [],
      "source": [
        "# ---------------- Cell 11: Fine-tune - unfreeze top layers of backbone ----------------\n",
        "# Strategy: unfreeze a fraction of top layers (closer to output)\n",
        "# Option: unfreeze last N layers or unfreeze by layer name.\n",
        "# Here we unfreeze the top convolutional block (last 20% of layers).\n",
        "\n",
        "# Count layers and decide cutoff\n",
        "total_layers = len(base_model.layers)\n",
        "# Choose how many layers to unfreeze (e.g., last 20%)\n",
        "pct_unfreeze = 0.2\n",
        "num_to_unfreeze = int(total_layers * pct_unfreeze)\n",
        "cutoff = total_layers - num_to_unfreeze\n",
        "\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "    layer.trainable = True if i >= cutoff else False\n",
        "\n",
        "print(\"Total backbone layers:\", total_layers)\n",
        "print(\"Unfrozen layers (trainable):\", sum([1 for l in base_model.layers if l.trainable]))\n",
        "\n",
        "# Re-compile with lower learning rate for fine-tuning\n",
        "fine_tune_lr = 1e-4\n",
        "optimizer_finetune = keras.optimizers.SGD(learning_rate=fine_tune_lr, momentum=0.9)\n",
        "model.compile(optimizer=optimizer_finetune, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fa8678e-27e2-49b8-b9c6-720e15861059",
      "metadata": {
        "id": "0fa8678e-27e2-49b8-b9c6-720e15861059"
      },
      "outputs": [],
      "source": [
        "# ---------------- Cell 12: Continue training (fine-tuning) ----------------\n",
        "EPOCHS_FINETUNE = 2\n",
        "\n",
        "history_finetune = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS_FINETUNE,\n",
        "    callbacks=callbacks,\n",
        "    verbose=2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa2d2886-1b50-4f9b-8312-954bf9778279",
      "metadata": {
        "id": "fa2d2886-1b50-4f9b-8312-954bf9778279"
      },
      "outputs": [],
      "source": [
        "# ---------------- Cell 13: Final evaluation on validation / test set ----------------\n",
        "test_gen = val_datagen.flow_from_directory(TEST_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False) if os.path.isdir(TEST_DIR) else None\n",
        "\n",
        "if test_gen is not None:\n",
        "    test_loss, test_acc = model.evaluate(test_gen, verbose=0)\n",
        "    print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}\")\n",
        "else:\n",
        "    val_loss, val_acc = model.evaluate(val_ds, verbose=0)\n",
        "    print(f\"Validation loss (final): {val_loss:.4f}, Validation accuracy (final): {val_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc9fb700-2484-4ad4-85a7-89444e1afa36",
      "metadata": {
        "id": "dc9fb700-2484-4ad4-85a7-89444e1afa36"
      },
      "outputs": [],
      "source": [
        "# ---------------- Cell 14: Visualize some predictions ----------------\n",
        "# Create an iterator for the validation dataset\n",
        "val_iter = iter(val_ds)\n",
        "\n",
        "# Get the next batch\n",
        "x_batch, y_batch = next(val_iter)\n",
        "\n",
        "# Predict\n",
        "preds = model.predict(x_batch)\n",
        "pred_labels = np.argmax(preds, axis=1)\n",
        "true_labels = np.argmax(y_batch, axis=1)\n",
        "\n",
        "# Plot first 12 images with true and predicted labels\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "for i in range(min(12, x_batch.shape[0])):\n",
        "    ax = plt.subplot(3,4,i+1)\n",
        "    plt.imshow(x_batch[i])\n",
        "    plt.title(f\"True: {list(class_indices.keys())[true_labels[i]]}\\nPred: {list(class_indices.keys())[pred_labels[i]]}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7aadc4e-d9fa-41a7-84e3-6e60617e786c",
      "metadata": {
        "id": "e7aadc4e-d9fa-41a7-84e3-6e60617e786c"
      },
      "outputs": [],
      "source": [
        "# ---------------- Cell 15: Save final model and tips ----------------\n",
        "model.save(\"transfer_finetuned_model.keras\")\n",
        "print(\"Saved model to transfer_finetuned_model.keras\")\n",
        "\n",
        "# Tips:\n",
        "# - If validation accuracy is poor: try stronger augmentation, more training epochs,\n",
        "#   or use a deeper backbone (ResNet50 / EfficientNet) and larger IMG_SIZE.\n",
        "# - For very large datasets, use tf.data pipeline for performance instead of ImageDataGenerator.\n",
        "# - If using VGG16 with small input (32x32), note pretrained ImageNet weights expect >=32x32; prefer 224x224 for VGG.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ac97f30-ee8d-4877-939b-d4387cc7931f",
      "metadata": {
        "id": "2ac97f30-ee8d-4877-939b-d4387cc7931f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}