{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99933e3f-8110-40b6-b8ea-ba5d175f21f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 - Setup\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c10cb0ba-5998-479b-b336-01b8f524528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility (best effort; GPU ops may still be non-deterministic)\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# This cell sets a random seed so the results are the same every time you run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3429c809-bc1f-4729-9885-b9e93ab11698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.6\n",
      "Numpy: 1.26.4\n",
      "TensorFlow: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "# Print versions to help reproducibility/debugging\n",
    "print(\"Python:\", os.sys.version.split()[0])\n",
    "print(\"Numpy:\", np.__version__)\n",
    "print(\"TensorFlow:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4511997-0591-446e-a4f5-82e0b603ff3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape: (60000, 28, 28)\n",
      "Train y shape: (60000,)\n",
      "Test  X shape: (10000, 28, 28)\n",
      "Test  y shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 - Dataset selection\n",
    "DATASET = \"mnist\"\n",
    "\n",
    "# MNIST: 28x28 grayscale images, labels 0-9\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "input_shape = x_train.shape[1:]  # (28,28)\n",
    "num_channels = 1\n",
    "num_classes = 10\n",
    "\n",
    "# Quick shapes print\n",
    "print(\"Train X shape:\", x_train.shape)\n",
    "print(\"Train y shape:\", y_train.shape)\n",
    "print(\"Test  X shape:\", x_test.shape)\n",
    "print(\"Test  y shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ➡ Here we get:\n",
    "# •\tx_train: 60,000 images for training\n",
    "# •\ty_train: labels (0–9) for each image\n",
    "# •\tx_test: 10,000 images for testing\n",
    "# •\ty_test: labels for testing\n",
    "# Each MNIST image is 28×28 pixels, black and white.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d87e998d-f946-461d-9db8-f5cc8262f42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vector size (flattened): 784\n",
      "Labels reshaped to: (60000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 - Preprocessing\n",
    "# Convert to float32 and scale to [0,1]\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test  = x_test.astype(\"float32\")  / 255.0\n",
    "\n",
    "# If MNIST, add channel dimension so shapes are consistent (N,28,28,1)\n",
    "if DATASET.lower() == \"mnist\":\n",
    "    x_train = np.expand_dims(x_train, axis=-1)  # (N,28,28,1)\n",
    "    x_test  = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# For feedforward (fully connected) network we will flatten images to vectors\n",
    "input_vector_size = int(np.prod(x_train.shape[1:]))  # e.g., 28*28*1 = 784 or 32*32*3 = 3072\n",
    "print(\"Input vector size (flattened):\", input_vector_size)\n",
    "\n",
    "# We will use sparse integer labels with SparseCategoricalCrossentropy (no one-hot conversion needed).\n",
    "# But ensure y_train / y_test shapes are (N,) not (N,1) for CIFAR:\n",
    "y_train = y_train.reshape(-1,)\n",
    "y_test  = y_test.reshape(-1,)\n",
    "print(\"Labels reshaped to:\", y_train.shape, y_test.shape)\n",
    "\n",
    "\n",
    "# This step does:\n",
    "# 1.\tConverts data type to float.\n",
    "# 2.\tDivides by 255 → so pixel values become between 0 and 1 (makes learning easier).\n",
    "# 3.\tFlattens each 28×28 image into a single long row of 784 numbers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a44b84f9-c41d-4c52-b3dd-6c36d3f961e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 4 - Visual check\n",
    "plt.figure(figsize=(8,4))\n",
    "n_show = 8\n",
    "for i in range(n_show):\n",
    "    ax = plt.subplot(2, n_show//2, i+1)\n",
    "    # For MNIST grayscale squeeze channel; for CIFAR color keep channels\n",
    "    img = x_train[i].squeeze()\n",
    "    if img.ndim == 2:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "    plt.title(f\"Label: {y_train[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# This cell displays a few sample images from the training data to visually check they loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ccec393-ddde-4306-834d-a3521f0660bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ffn_flattened\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ffn_flattened\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m401,920\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m2,570\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">535,818</span> (2.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m535,818\u001b[0m (2.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">535,818</span> (2.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m535,818\u001b[0m (2.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 5 - Define model (Feedforward / Fully-connected network)\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "hidden_units = [512, 256]   # two hidden layers: you can change sizes\n",
    "dropout_rate = 0.3          # dropout to reduce overfitting\n",
    "activation = \"relu\"\n",
    "\n",
    "model = models.Sequential(name=\"ffn_flattened\")\n",
    "# Input: flatten the image to a vector\n",
    "model.add(layers.Input(shape=(input_vector_size,)))\n",
    "model.add(layers.Dense(hidden_units[0], activation=activation, name=\"dense_1\"))\n",
    "model.add(layers.Dropout(dropout_rate, name=\"dropout_1\"))\n",
    "model.add(layers.Dense(hidden_units[1], activation=activation, name=\"dense_2\"))\n",
    "model.add(layers.Dropout(dropout_rate, name=\"dropout_2\"))\n",
    "# Output layer: num_classes with softmax for classification\n",
    "model.add(layers.Dense(num_classes, activation=\"softmax\", name=\"output\"))\n",
    "\n",
    "# Show model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Explanation:\n",
    "# •\tOptimizer: SGD (Stochastic Gradient Descent) → updates weights gradually to reduce error.\n",
    "# •\tLearning rate: how fast the model learns.\n",
    "# •\tLoss: measures how far predictions are from correct answers.\n",
    "# •\tMetrics: accuracy shows performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "915ec112-1841-43eb-b2d5-7243811efea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 - Compile with SGD optimizer\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "# We use sparse categorical crossentropy because labels are integer class indices (0..9)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# This cell compiles the model using the SGD optimizer and sets loss function and accuracy as metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c616201-30a6-4ae0-89d2-1196e2af7fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_flat shape: (60000, 784)\n",
      "x_test_flat  shape: (10000, 784)\n",
      "Using validation set of size: 6000\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 - Flatten training and test images into vectors for FFN\n",
    "x_train_flat = x_train.reshape((-1, input_vector_size))\n",
    "x_test_flat  = x_test.reshape((-1, input_vector_size))\n",
    "\n",
    "print(\"x_train_flat shape:\", x_train_flat.shape)\n",
    "print(\"x_test_flat  shape:\", x_test_flat.shape)\n",
    "\n",
    "# Optionally create a validation split from training set (useful for monitoring)\n",
    "val_split = 0.1\n",
    "val_count = int(x_train_flat.shape[0] * val_split)\n",
    "if val_count > 0:\n",
    "    x_val_flat = x_train_flat[-val_count:]\n",
    "    y_val = y_train[-val_count:]\n",
    "    x_train_flat = x_train_flat[:-val_count]\n",
    "    y_train = y_train[:-val_count]\n",
    "    print(\"Using validation set of size:\", x_val_flat.shape[0])\n",
    "else:\n",
    "    x_val_flat, y_val = None, None\n",
    "\n",
    "\n",
    "# This cell flattens 2D image data into 1D vectors so it can be used by the feedforward network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660e7904-7e19-454d-8301-d3dbdfcd2aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "844/844 - 10s - 12ms/step - accuracy: 0.8704 - loss: 0.4276 - val_accuracy: 0.9592 - val_loss: 0.1441\n",
      "Epoch 2/15\n",
      "844/844 - 9s - 11ms/step - accuracy: 0.9427 - loss: 0.1935 - val_accuracy: 0.9717 - val_loss: 0.0999\n",
      "Epoch 3/15\n",
      "844/844 - 9s - 11ms/step - accuracy: 0.9572 - loss: 0.1417 - val_accuracy: 0.9758 - val_loss: 0.0857\n",
      "Epoch 4/15\n",
      "844/844 - 9s - 10ms/step - accuracy: 0.9649 - loss: 0.1158 - val_accuracy: 0.9767 - val_loss: 0.0795\n",
      "Epoch 5/15\n",
      "844/844 - 9s - 11ms/step - accuracy: 0.9703 - loss: 0.0978 - val_accuracy: 0.9798 - val_loss: 0.0704\n",
      "Epoch 6/15\n",
      "844/844 - 8s - 10ms/step - accuracy: 0.9741 - loss: 0.0841 - val_accuracy: 0.9792 - val_loss: 0.0670\n",
      "Epoch 7/15\n",
      "844/844 - 9s - 10ms/step - accuracy: 0.9772 - loss: 0.0733 - val_accuracy: 0.9815 - val_loss: 0.0645\n",
      "Epoch 8/15\n",
      "844/844 - 9s - 11ms/step - accuracy: 0.9797 - loss: 0.0649 - val_accuracy: 0.9817 - val_loss: 0.0618\n",
      "Epoch 9/15\n",
      "844/844 - 8s - 10ms/step - accuracy: 0.9817 - loss: 0.0588 - val_accuracy: 0.9817 - val_loss: 0.0656\n",
      "Epoch 10/15\n",
      "844/844 - 9s - 10ms/step - accuracy: 0.9829 - loss: 0.0542 - val_accuracy: 0.9832 - val_loss: 0.0610\n",
      "Epoch 11/15\n",
      "844/844 - 9s - 11ms/step - accuracy: 0.9848 - loss: 0.0472 - val_accuracy: 0.9822 - val_loss: 0.0654\n",
      "Epoch 12/15\n",
      "844/844 - 10s - 12ms/step - accuracy: 0.9855 - loss: 0.0462 - val_accuracy: 0.9835 - val_loss: 0.0610\n",
      "Epoch 13/15\n",
      "844/844 - 9s - 11ms/step - accuracy: 0.9879 - loss: 0.0396 - val_accuracy: 0.9843 - val_loss: 0.0617\n",
      "Epoch 14/15\n",
      "844/844 - 8s - 10ms/step - accuracy: 0.9882 - loss: 0.0380 - val_accuracy: 0.9817 - val_loss: 0.0601\n",
      "Epoch 15/15\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 - Train the model (Fixed for Keras 3.x)\n",
    "batch_size = 64\n",
    "epochs = 15\n",
    "\n",
    "callbacks = [\n",
    "    # Option 1: Recommended new format\n",
    "    keras.callbacks.ModelCheckpoint(\"best_ffn.keras\", save_best_only=True, monitor=\"val_loss\")\n",
    "    # Option 2 (alternative): uncomment below line if you prefer old .h5 weight format\n",
    "    # keras.callbacks.ModelCheckpoint(\"best_ffn.h5\", save_best_only=True, monitor=\"val_loss\", save_weights_only=True)\n",
    "] if x_val_flat is not None else []\n",
    "\n",
    "history = model.fit(\n",
    "    x_train_flat, y_train,\n",
    "    validation_data=(x_val_flat, y_val) if x_val_flat is not None else (x_test_flat, y_test),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Explanation:\n",
    "# •\tepochs: how many times the model sees the whole dataset.\n",
    "# •\tbatch_size: how many samples to process before updating weights.\n",
    "# •\tvalidation_split: 10% data is used for checking accuracy after each epoch.\n",
    "# As it trains, it prints loss and accuracy for both training and validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1447d026-b5d7-459b-9769-0cf3ae1b99d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 - Plot metrics\n",
    "hist = history.history\n",
    "epochs_range = range(1, len(hist['loss']) + 1)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs_range, hist['loss'], label='train_loss')\n",
    "# plot val_loss if available\n",
    "if 'val_loss' in hist:\n",
    "    plt.plot(epochs_range, hist['val_loss'], label='val_loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs_range, hist['accuracy'], label='train_acc')\n",
    "if 'val_accuracy' in hist:\n",
    "    plt.plot(epochs_range, hist['val_accuracy'], label='val_acc')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# This cell plots graphs showing how the loss and accuracy changed during training.\n",
    "# Helps you visualize:\n",
    "# •\tLoss curve: should go down with time.\n",
    "# •\tAccuracy curve: should go up with time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd8427c-e7bc-46f1-a21a-1e565c66e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 - Evaluate and test predictions\n",
    "test_loss, test_acc = model.evaluate(x_test_flat, y_test, verbose=0)\n",
    "print(f\"Test loss: {test_loss:.4f}    Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Predict probabilities on first 12 test samples and show images + predicted labels\n",
    "pred_probs = model.predict(x_test_flat[:12])\n",
    "pred_labels = np.argmax(pred_probs, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "for i in range(12):\n",
    "    ax = plt.subplot(3, 4, i+1)\n",
    "    img = x_test[i].squeeze()\n",
    "    if img.ndim == 2:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "    plt.title(f\"GT:{y_test[i]}  P:{pred_labels[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# This cell evaluates the model on the test dataset and prints its accuracy and loss.\n",
    "# It also predicts some test images and shows their predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8111fc-1993-478d-8b27-32c745129c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11 - Save model & example single-image predict helper\n",
    "model.save(\"ffn_model_final.keras\")   # ✅ Save model properly\n",
    "\n",
    "def predict_single_image(img_array, model):\n",
    "    \"\"\"\n",
    "    img_array : single image as numpy array, scaled to [0,1], with channel dims.\n",
    "    model expects flattened vector input.\n",
    "    \"\"\"\n",
    "    v = img_array.reshape(1, -1).astype(\"float32\")\n",
    "    probs = model.predict(v)\n",
    "    label = int(np.argmax(probs[0]))\n",
    "    conf = float(np.max(probs[0]))\n",
    "    return label, conf\n",
    "\n",
    "# Example usage (first test image)\n",
    "lbl, conf = predict_single_image(x_test[0], model)\n",
    "print(\"Predicted:\", lbl, \"Confidence:\", round(conf, 4), \"Ground truth:\", y_test[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03947c0d-3250-4fbd-b0c6-0a26502cdd61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
